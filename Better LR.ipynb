{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading https://files.pythonhosted.org/packages/91/55/8cb23a97301b177e9c8e3226dba45bb454411de2cbd25746763267f226c2/tqdm-4.28.1-py2.py3-none-any.whl (45kB)\n",
      "Installing collected packages: tqdm\n",
      "Successfully installed tqdm-4.28.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "distributed 1.21.8 requires msgpack, which is not installed.\n",
      "You are using pip version 10.0.1, however version 18.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque, Counter\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm \n",
    "import pandas as pd\n",
    "from heapq import nlargest\n",
    "\n",
    "#from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322890"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"cheetah.cs.fiu.edu-110108-113008.1.blkparse\"\n",
    "df = pd.read_csv(filename, sep=' ',header = None)\n",
    "df.columns = ['timestamp','pid','pname','blockNo', \\\n",
    "              'blockSize', 'readOrWrite', 'bdMajor', 'bdMinor', 'hash']\n",
    "blocktrace = df['blockNo'].tolist()\n",
    "len(blocktrace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def potential_eviction(Cache, upcoming_index, N):\n",
    "    index = upcoming_index.keys()\n",
    "    topN = nlargest(N, index)\n",
    "    evictionBlock = [upcoming_index[i] for i in topN]\n",
    "    evictionIndex = [list(Cache).index(i) for i in evictionBlock]\n",
    "    eviction = np.zeros(len(Cache), dtype=int)\n",
    "    eviction[evictionIndex] = 1\n",
    "    return eviction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def belady_opt(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    infinite_index = 100 * len(blocktrace) \n",
    "    # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = set()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([], dtype=int).reshape(0,3*frame+1)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "                if len(upcoming_index) != 0:\n",
    "                    \n",
    "                    # find the farthest i.e. max_index in upcoming_index\n",
    "                    max_index = max(upcoming_index)\n",
    "                    \n",
    "                    if (i % 100 +1 == 100):\n",
    "                        blockNo = np.array([i for i in Cache], dtype=int)\n",
    "                        normBlock = blockNo / np.linalg.norm(blockNo)\n",
    "                        recency_ = np.array([recency.index(i) for i in Cache], dtype=int)\n",
    "                        normRecent = recency_ / np.linalg.norm(recency_)\n",
    "                        frequency_ = np.array([frequency[i] for i in Cache], dtype=int)\n",
    "                        Normfrequent = frequency_ / np.linalg.norm(frequency_)\n",
    "                        stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                        print(max_index)\n",
    "                        break\n",
    "                        stack = np.append(stack, max_index)\n",
    "                        dataset = np.vstack((dataset, stack))\n",
    "\n",
    "                    \n",
    "                    # remove the block with max_index from cache\n",
    "                    Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove the block with max_index from recency dict\n",
    "                    recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove max_index element from upcoming_index\n",
    "                    del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index += 1\n",
    "                \n",
    "            # add block into Cache\n",
    "            Cache.add(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='buidling index', max=1322890, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f2b846602e437998d7251ccd633690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='sequence', max=1322890, style=ProgressStyle(description_width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132289493\n",
      "\r"
     ]
    }
   ],
   "source": [
    "hitrate, dataset = belady_opt(blocktrace, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[283193344,        39,         2, ...,       295,         2,\n",
       "        132289493],\n",
       "       [283193344,        39,         2, ...,       295,         2,\n",
       "        132289543],\n",
       "       [283193344,        39,         2, ...,       295,         2,\n",
       "        132289474],\n",
       "       ...,\n",
       "       [277180416,       327,         5, ...,       326,         5,\n",
       "        132960436],\n",
       "       [277180416,       327,         5, ...,       326,         5,\n",
       "        132960536],\n",
       "       [277180416,       327,         5, ...,       326,         5,\n",
       "        132960636]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.00\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:,:3], dataset[:,-1].astype(int) ,test_size=0.3, random_state=0, shuffle=False)\n",
    "\n",
    "#Fitting Logistic Regression Model\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "\n",
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, Y_test)))\n",
    "\n",
    "confusion_matrix = confusion_matrix(Y_test,Y_pred)\n",
    "print (confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourcache(blocktrace, frame):\n",
    "    '''\n",
    "    INPUT\n",
    "    ==========\n",
    "    blocktrace = list of block request sequence\n",
    "    frame = size of the cache\n",
    "    \n",
    "    OUTPUT\n",
    "    ==========\n",
    "    hitrate \n",
    "    '''\n",
    "    infinite_index = 100 * len(blocktrace) \n",
    "    # should be a large integer\n",
    "    \n",
    "    block_index = defaultdict(deque) \n",
    "    # dictionary with block number as key and list\n",
    "    # of index value in blocktrace\n",
    "    \n",
    "    upcoming_index = defaultdict(int)\n",
    "    # dictionary with index number as key and value as block\n",
    "    \n",
    "    frequency = defaultdict(int)\n",
    "    # dictionary of block as key and number\n",
    "    # of times it's been requested so far\n",
    "    \n",
    "    recency = list()\n",
    "    # list of block in order of their request\n",
    "    \n",
    "    Cache = set()\n",
    "    # Cache with block\n",
    "    \n",
    "    dataset = np.array([], dtype=int).reshape(0,3*frame+1)\n",
    "    \n",
    "    hit, miss = 0, 0\n",
    "    \n",
    "    # populate the block_index\n",
    "    for i, block in enumerate(tqdm(blocktrace, \\\n",
    "                              desc=\"buidling index\", leave=False)):\n",
    "        block_index[block].append(i)\n",
    "        \n",
    "    # sequential block requests start\n",
    "    for i, block in enumerate(tqdm(blocktrace, desc=\"sequence\", leave=False)):\n",
    "        \n",
    "        # increament the frequency number for the block\n",
    "        frequency[block] += 1\n",
    "        \n",
    "        # make sure block has the value in block_index dictionary \n",
    "        # as current seq_number\n",
    "        if len(block_index[block]) != 0 and block_index[block][0] == i:\n",
    "            \n",
    "            # if yes, remove the first element of block_index[block]\n",
    "            block_index[block].popleft()\n",
    "        \n",
    "        # if block exist in current cache\n",
    "        if block in Cache:\n",
    "            \n",
    "            # increment hit\n",
    "            hit += 1\n",
    "            \n",
    "            # update the recency\n",
    "            recency.remove(block)\n",
    "            recency.append(block)\n",
    "            \n",
    "            # update upcoming_index\n",
    "            if i in upcoming_index:\n",
    "                \n",
    "                # delete old index\n",
    "                del upcoming_index[i]\n",
    "        \n",
    "                if len(block_index[block]) is not 0:\n",
    "                    # add new upcoming index\n",
    "                    upcoming_index[block_index[block][0]] = block\n",
    "                    # remove index from block_index\n",
    "                    block_index[block].popleft()\n",
    "                else:\n",
    "                    # add a large integer as index\n",
    "                    upcoming_index[infinite_index] = block\n",
    "                    # increament large integer\n",
    "                    infinite_index+=1\n",
    "           \n",
    "        # block not in current cache\n",
    "        else:\n",
    "            \n",
    "            # increament miss\n",
    "            miss += 1\n",
    "            \n",
    "            # if cache has no free space\n",
    "            if len(Cache) == frame:\n",
    "                \n",
    "                \n",
    "                # evict the farthest block in future request from cache\n",
    "                if len(upcoming_index) != 0:\n",
    "                    \n",
    "                    # find the farthest i.e. max_index in upcoming_index\n",
    "                    max_index = max(upcoming_index)\n",
    "                    \n",
    "                    if (i % 100 +1 == 100):\n",
    "                        blockNo = np.array([i for i in Cache], dtype=int)\n",
    "                        normBlock = blockNo / np.linalg.norm(blockNo)\n",
    "                        recency_ = np.array([recency.index(i) for i in Cache], dtype=int)\n",
    "                        normRecent = recency_ / np.linalg.norm(recency_)\n",
    "                        frequency_ = np.array([frequency[i] for i in Cache], dtype=int)\n",
    "                        Normfrequent = frequency_ / np.linalg.norm(frequency_)\n",
    "                        stack = np.column_stack((blockNo, recency_, frequency_)).reshape(1,frame*3)\n",
    "                        stack = np.append(stack, upcoming_index[max_index])\n",
    "                        dataset = np.vstack((dataset, stack))\n",
    "\n",
    "                    \n",
    "                    # remove the block with max_index from cache\n",
    "                    Cache.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove the block with max_index from recency dict\n",
    "                    recency.remove(upcoming_index[max_index])\n",
    "                    \n",
    "                    # remove max_index element from upcoming_index\n",
    "                    del upcoming_index[max_index]\n",
    "                    \n",
    "            # add upcoming request of current block in upcoming_index\n",
    "            if len(block_index[block]) != 0:\n",
    "                \n",
    "                # add upcoming index of block\n",
    "                upcoming_index[block_index[block][0]] = block\n",
    "               \n",
    "                # remove the index from block_index \n",
    "                block_index[block].popleft()\n",
    "            \n",
    "            else:\n",
    "                \n",
    "                # add a large integer as index\n",
    "                upcoming_index[infinite_index] = block\n",
    "                \n",
    "                # increament high number\n",
    "                infinite_index += 1\n",
    "                \n",
    "            # add block into Cache\n",
    "            Cache.add(block)\n",
    "            \n",
    "            # add block into recency\n",
    "            recency.append(block)\n",
    "            \n",
    "            \n",
    "    # calculate hitrate\n",
    "    hitrate = hit / (hit + miss)\n",
    "\n",
    "    return hitrate, dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
